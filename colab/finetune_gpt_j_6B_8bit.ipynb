{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanGoslenko/Data_Science/blob/main/colab/finetune_gpt_j_6B_8bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLzX_EPqAnEW"
      },
      "source": [
        "### Fine-tuning 6-Billion GPT-J in colab with LoRA and 8-bit compression\n",
        "\n",
        "This notebook is a proof of concept for fine-tuning [GPT-J-6B](https://huggingface.co/EleutherAI/gpt-j-6B) with limited memory. A detailed explanation of how it works can be found in [this model card](https://huggingface.co/hivemind/gpt-j-6B-8bit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op0GXmC8CCyR",
        "outputId": "e1812167-22f4-450d-94c8-89719a94e37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.14.1 in /usr/local/lib/python3.8/dist-packages (4.14.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (0.0.53)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.14.1) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.14.1) (2022.12.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.14.1) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/dist-packages (0.37.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement bitsandbytes-cuda111==0.26.0 (from versions: 0.26.0.post2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for bitsandbytes-cuda111==0.26.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets==1.16.1 in /usr/local/lib/python3.8/dist-packages (1.16.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (2.25.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (2023.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (0.12.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (3.8.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (0.70.14)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets==1.16.1) (3.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets==1.16.1) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.16.1) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.16.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.16.1) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.16.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.16.1) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==1.16.1) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.16.1) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.14.1\n",
        "!pip install bitsandbytes\n",
        "!pip install bitsandbytes-cuda111==0.26.0\n",
        "!pip install datasets==1.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p0dy1ZFwClcq",
        "outputId": "a7556230-f52a-472a-e0b5-ddcbbab3bf20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GODiktIBFt4w"
      },
      "source": [
        "### Converting the model to 8 bits.\n",
        "\n",
        "We convert EleutherAI's GPT-J-6B model to 8 bits using facebook's [bitsandbytes](https://github.com/facebookresearch/bitsandbytes) library. This reduces the model's size from 20Gb down to just 6Gb.\n",
        "\n",
        "Note that we don't convert linear layer biases to 8 bit as they take up less that 1% of the model's weight anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P8Y75B6WDIN-"
      },
      "outputs": [],
      "source": [
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        " \n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias).clone()\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output\n",
        " \n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        " \n",
        " \n",
        "class DequantizeAndLinear(torch.autograd.Function): \n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias)\n",
        " \n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        " \n",
        " \n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        " \n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output \n",
        " \n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        " \n",
        " \n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        " \n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        " \n",
        " \n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr( \n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BOSZ-S1cDRq1"
      },
      "outputs": [],
      "source": [
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "        \n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pthEhmDBSyEm"
      },
      "outputs": [],
      "source": [
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuW4H6HTS82r",
        "outputId": "a5f9ca6a-0bd1-407d-d896-759a58d01cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "lm_head Linear(in_features=4096, out_features=50400, bias=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJForCausalLM(\n",
              "  (transformer): GPTJModel(\n",
              "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (24): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (25): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (26): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (27): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRF2QqvzENCr"
      },
      "source": [
        "### Text generation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJd45kFaZ1Ba",
        "outputId": "42064c90-37d2-4197-907e-f9d6f767300f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Generate code that creates a simple convolutional neural netwotk in pytorch.\n",
            "\n",
            "Answer: \n",
            "\n",
            "import tensorflow as tf import tensorflow.compat.v1 as tf \n",
            "from tensorflow import keras\n",
            "\n",
            "# create weights\n",
            "weights = keras.Sequential( \n",
            "    [\n",
            "        # the first two inputs are the same as ours so we will assign a weight of 1 to them\n",
            "        keras.Input(shape=(1,1,1,1)),\n",
            "        # a kernel \n",
            "        # the convolutional layer has a kernel of 5x5\n",
            "        keras.Input(shape=(5,5,1,1)), \n",
            "        # an output\n",
            "        keras.Input(shape=(1,1,1,1))\n",
            "    ])\n",
            "\n",
            "# the bias is the same as ours\n",
            "weights.add(keras.Input(shape=(1,1,1,1)))\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Instruction: Generate code that creates a simple convolutional neural netwotk in pytorch.\n",
        "\n",
        "Answer: \"\"\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "generated_ids = gpt.generate(input_ids,\n",
        "                             do_sample=True,\n",
        "                             temperature=0.9,\n",
        "                             max_length=256)\n",
        "generated_text = tokenizer.decode(generated_ids[0])\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfdLQHOuEU7h"
      },
      "source": [
        "### LoRA fine-tuning example\n",
        "Here we demonstrate how to fine-tune the proposed model using low-rank adapters [(Hu et al, 2021)](https://arxiv.org/abs/2106.09685) and [8-bit Adam](https://arxiv.org/abs/2110.02861). We also use [dataset streaming API](https://huggingface.co/docs/datasets/dataset_streaming.html) to avoid downloading the large dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V5ctu4Q5aq-g",
        "outputId": "fcf0fe4b-cb96-4b05-a0ff-1bc568436e6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJForCausalLM(\n",
              "  (transformer): GPTJModel(\n",
              "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (24): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (25): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (26): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (27): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def add_adapters(model, adapter_dim=16):\n",
        "    assert adapter_dim > 0\n",
        "\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, FrozenBNBLinear):\n",
        "            module.adapter = nn.Sequential(\n",
        "                nn.Linear(module.in_features, adapter_dim, bias=False),\n",
        "                nn.Linear(adapter_dim, module.out_features, bias=False),\n",
        "            )\n",
        "            nn.init.zeros_(module.adapter[1].weight)\n",
        "        elif isinstance(module, FrozenBNBEmbedding):\n",
        "            module.adapter = nn.Sequential(\n",
        "                nn.Embedding(module.num_embeddings, adapter_dim),\n",
        "                nn.Linear(adapter_dim, module.embedding_dim, bias=False),\n",
        "            )\n",
        "            nn.init.zeros_(module.adapter[1].weight)\n",
        "\n",
        "add_adapters(gpt)\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_for_optimizer = [\n",
        "    name for (name, param) in gpt.named_parameters()\n",
        "    if \"attn\" in name and \"adapter\" in name\n",
        "]\n",
        "print(\"Trainiable params:\", len(params_for_optimizer))"
      ],
      "metadata": {
        "id": "Neo03L6UXGl-",
        "outputId": "7b2446a8-dd27-49e9-b0b1-ad79c16188c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainiable params: 224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in gpt.named_parameters():\n",
        "    if name not in params_for_optimizer:\n",
        "        #print(f\"Setting {name} requires_grad=False\")\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "-v8zBE62XMb9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('small_train.txt', 'r') as f:\n",
        "    train = f.readlines()\n",
        "\n",
        "with open('small_test.txt', 'r') as f:\n",
        "    test = f.readlines()"
      ],
      "metadata": {
        "id": "Qd3X8D31TGOH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[:2000]\n",
        "len(train)"
      ],
      "metadata": {
        "id": "z4Vqbyc9ONy0",
        "outputId": "718b0441-3f82-4f1f-d0a6-016fc75361bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIlHG9Wk0WaJ",
        "outputId": "54ffdb70-061f-4e18-c746-2c76757c6ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "68537c4d2a104f1c83fa9c9480382172",
            "4801f03243de45ac91843ae0f4153a94",
            "000be633dc1342aeae502ca85090b373",
            "6ef5b563cb6241b589ca1d44bb74d101",
            "4393113513fe449995ad4f4f71cceea1",
            "c0390b09d8f141e594d8ac9274211dbb",
            "8543cc8d203449c38dcd61011adaf346",
            "5d360cd3269b494aaed85aa45e2fcac2",
            "72cf39fff1444f079a3d2a3a4947011e",
            "f0e6fa43b9764ed7a030b5ac50673866",
            "0fe9850bd6bc402b88b0ce3272ad045d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68537c4d2a104f1c83fa9c9480382172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(4.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(66.5703, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(70.2079, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.7296, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1950, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(47.9190, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.7757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(322.3667, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.0351, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0829, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.4491, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7511, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7628, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5489, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.5370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0512, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2198, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.9373, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4039, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.1728, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.7810, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7198, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2238, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.8898, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.4452, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3986, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8813, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7283, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1035, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7387, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2145, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0273, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0755, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.1630, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(85.2755, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7790, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8589, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(47.4120, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(56.4924, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(89.2106, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(92.9561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(187.7145, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(75.4898, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.3114, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(61.8963, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.4154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(224.8328, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(81.9646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.3847, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.0668, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2311, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.7854, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.7573, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.6522, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.7003, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7790, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.8822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(358.5856, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.7436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(114.8447, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(143.6719, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(63.3388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(70.0100, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.8456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(127.1802, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.8391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(126.3497, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.7954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(120.9476, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.1594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(174.0523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(214.1989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(49.4468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.5884, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8192, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.6152, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(143.0661, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(135.0854, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(144.3031, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(147.4133, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(6.7547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(858.0894, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4213, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.7009, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(44.5520, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(6.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(488.5739, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(58.7497, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.3544, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(36.9802, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.3915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5066, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.3358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.3991, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(90.8498, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7050, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8583, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9729, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(40.0460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(76.7925, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.6273, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.6200, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4399, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4316, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6441, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7435, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.6679, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3488, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8664, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4236, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0169, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9884, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7033, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1624, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8333, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8275, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3103, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9508, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9219, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9559, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3603, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.1948, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5096, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1488, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9676, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0836, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8325, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3163, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7867, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8586, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4085, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6753, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5366, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9440, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5410, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7589, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6032, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6799, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5339, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5986, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.1941, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0784, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.1443, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1643, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7831, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9059, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1625, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6941, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6035, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.5320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.3735, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5210, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.5170, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7316, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.3226, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.1410, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1602, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1269, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6786, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8931, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4551, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(76.2722, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.9293, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6837, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4996, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.8461, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.5581, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7643, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.9247, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6013, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7356, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9665, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0273, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.5769, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5599, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4939, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.2995, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6437, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.1437, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6556, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8573, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0187, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6884, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2210, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.4054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3632, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.8895, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2030, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8182, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9336, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7549, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3611, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2564, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8543, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8200, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9117, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9633, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7046, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0071, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.1586, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(46.9377, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6578, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0974, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5620, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5066, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7863, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3785, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5262, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0110, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6455, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2436, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4827, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.3564, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.1865, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8557, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(47.2636, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.1091, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.6772, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2895, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.4026, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0392, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.6936, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2809, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.3822, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4490, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.6447, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2337, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.5904, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.5094, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4879, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.5820, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.9482, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5936, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3611, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.0297, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.9135, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1928, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.6369, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.4760, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.0438, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.0504, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.8400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4230, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(35.0417, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.5957, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6006, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7423, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.9568, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(54.4862, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(66.5703, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(29.0284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3575, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9994, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0203, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5473, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4216, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5841, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8017, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.3647, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1390, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.7039, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7306, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.8626, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9132, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9694, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6329, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0435, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8036, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.3241, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0182, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7264, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8387, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2211, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9323, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.7789, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.6072, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.1261, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.8165, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3343, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0104, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1732, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8871, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5149, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5387, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5826, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7643, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0767, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6607, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.2378, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6936, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4961, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2019, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.1772, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0394, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0384, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9389, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0875, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5661, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9787, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7363, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9501, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4181, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8306, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5907, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.9800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7354, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.2960, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0855, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1877, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.1953, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8444, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.6392, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8975, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6567, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5218, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9322, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(45.3383, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(45.7845, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.1619, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(55.6096, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(45.5189, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.4131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(75.8662, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.4760, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.6789, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.6591, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.9518, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(64.6045, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.5733, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5900, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0833, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(47.3511, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6227, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3155, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.4158, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.3744, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.2412, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(62.8579, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4252, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.0829, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.7644, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.2747, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1448, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.4528, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(29.8765, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(85.6963, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5673, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0848, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.0296, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0668, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.3875, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1701, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.8095, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8583, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7547, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1527, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2335, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(73.5240, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.9870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.5253, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(45.3548, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(67.5604, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.4393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1150, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.4675, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7000, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.4349, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.4362, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8512, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(42.2774, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(73.5240, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(36.8318, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(93.9828, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(48.7438, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(86.8150, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(51.5493, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.4057, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.4458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.2351, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.0230, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.8226, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(53.8271, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.4619, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(75.5659, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.8186, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9515, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.1277, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.1499, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9710, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.8421, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.0224, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3043, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2379, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3898, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1686, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6467, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7685, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2196, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7763, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9702, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9337, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8041, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8211, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1111, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1069, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.3078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.8145, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2650, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.8622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.5033, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.9687, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6996, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9547, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2046, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.5837, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7671, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.2550, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.6868, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5222, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.1935, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(73.5240, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.5307, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(6.6558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(777.3012, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(78.9175, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(78.4262, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.5827, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.3019, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(70.0669, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.2050, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9755, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3978, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.7298, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4252, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4247, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7528, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7798, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.3461, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.6259, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7260, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7927, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6958, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.0612, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2802, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4516, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4839, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4256, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7060, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.9927, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.6652, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.4909, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.2109, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.9363, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1809, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1279, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3978, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.9823, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4252, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3978, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0864, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3175, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.7644, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.2747, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7643, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.5902, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.5205, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.2712, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.0954, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(40.0460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5673, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1028, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7628, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(35.8924, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.4268, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.6605, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.1606, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.4015, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.3959, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0795, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(64.8903, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8513, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(55.1317, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(6.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(495.1174, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(66.7372, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(76.6295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2382, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.5692, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.7024, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(74.9412, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4714, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.1595, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(56.6472, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(54.8158, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(68.3874, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(49.6057, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.4360, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(87.5043, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.7825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(119.4046, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(55.1441, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8513, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.1370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5900, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.7150, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(43.3900, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.6302, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4152, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.9600, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(65.5777, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1334, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3378, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6241, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1505, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7276, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7332, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(66.5218, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(97.4569, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(93.4197, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(96.0457, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.1612, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.6256, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.4320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7343, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.1969, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(59.4658, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.2426, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.7826, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.9744, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1851, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(61.8518, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.7698, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.8481, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(94.7888, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3537, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9039, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9402, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9183, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(72.2821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.6041, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(58.0086, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1326, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6010, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7643, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6903, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4558, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(62.7337, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0178, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.2105, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.3600, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.6698, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.4504, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8428, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9073, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.0683, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.3102, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5599, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(40.0460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(83.3376, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9509, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6203, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.1090, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0986, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0410, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4470, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3255, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8847, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0146, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9213, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9141, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4171, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4454, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8426, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4641, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6891, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1964, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9515, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2128, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9631, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7222, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6616, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3137, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.9709, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4667, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.5331, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.0253, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2210, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.4054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7628, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3314, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7000, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(64.8903, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.7543, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.7614, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.9552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(36.4839, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7930, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9529, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9708, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0140, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6583, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(79.4279, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.1105, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7674, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2392, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.2072, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.8307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(125.2933, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.4890, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9434, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9803, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1234, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0752, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.1748, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8481, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7536, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.8552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2896, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.6175, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.1546, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.2342, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6068, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7117, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5176, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9898, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0229, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.8552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6349, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8211, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0885, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9215, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.8552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7214, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4507, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0885, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6787, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.4500, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.6169, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.0572, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0790, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.8552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(7.8771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2636.1624, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6302, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4714, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7354, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8449, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(46.0329, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.2598, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.7850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3277, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3199, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9019, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5613, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9531, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.4101, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(136.9456, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.7371, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4597, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0920, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2223, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2306, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2874, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9979, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1988, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7977, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8446, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7704, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1548, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3324, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.0890, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7109, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9987, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3324, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.3231, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7861, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0549, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3324, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.5612, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2161, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6676, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3324, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.0332, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1225, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1767, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.2005, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4930, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4592, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2784, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9308, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6723, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.8883, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.2439, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.0946, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.1269, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.4149, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7511, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9979, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3542, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7977, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2709, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7758, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.5320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4045, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8903, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.8627, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7535, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1642, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0098, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8335, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.6355, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2151, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8883, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4930, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4592, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2784, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9308, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3158, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.2136, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.2801, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.0999, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.3011, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.0448, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2272, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5685, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2876, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2823, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.9032, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6142, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5928, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.3985, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7426, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8702, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3085, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8843, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9008, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7606, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3365, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7272, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5749, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9867, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6647, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8569, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4691, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.1131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.6880, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4391, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.5303, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8482, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0952, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.6934, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1494, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.5706, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.5533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9755, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9811, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8430, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8843, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.4216, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7606, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.8114, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.5502, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3243, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6631, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.3403, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9301, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7489, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1785, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0984, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5455, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.6125, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8836, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6032, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0701, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.5017, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3339, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6032, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2292, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6841, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.5211, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2430, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2493, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5599, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5066, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4510, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3252, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7040, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8014, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7245, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7286, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5480, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2920, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8534, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6860, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7727, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4547, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7001, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6828, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7165, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0390, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0386, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6723, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3397, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.6299, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6301, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4164, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3737, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6790, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4085, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1707, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3282, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9083, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0557, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7143, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7100, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0263, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.7922, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7383, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.5036, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4485, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2880, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6257, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8056, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1302, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6215, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4893, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1180, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5456, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4095, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1202, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.3137, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4585, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0034, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1083, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7495, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5916, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8457, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4520, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7424, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6322, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3757, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0817, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0443, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2447, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2197, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5432, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0357, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9680, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0101, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9159, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9783, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0642, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5289, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4779, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8812, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(35.4360, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.5571, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4478, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3988, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2502, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4779, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9611, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8238, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.6794, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0758, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3647, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3590, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5854, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4677, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9256, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9181, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7377, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.8866, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7377, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7203, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4211, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2200, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6545, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8661, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.1176, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1631, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7770, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.1446, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1983, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7198, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(93.9689, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8886, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5294, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6607, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9992, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1563, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3461, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5580, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5673, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4963, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2004, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8602, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2994, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1060, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5146, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.7976, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9467, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0631, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4317, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0970, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5288, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2765, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2726, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3112, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2970, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6098, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0975, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7391, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2390, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7566, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6545, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6803, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2369, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7841, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3522, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7113, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9081, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7603, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1311, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8536, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3356, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0003, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3877, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.3115, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2675, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.8472, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6603, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.0921, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6525, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0965, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2746, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9940, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5679, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2726, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7053, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9488, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0317, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.3115, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7995, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(89.1698, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(62.2942, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(83.6487, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.8116, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1657, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6420, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0381, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8536, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3356, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0003, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4698, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0183, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2734, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.5974, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(63.1468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(49.5229, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2031, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8513, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8492, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(77.3049, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6861, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.9860, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(43.1404, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(140.8167, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.2074, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(61.9993, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.6524, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.4645, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(33.3493, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(92.4370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(80.4134, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6436, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0633, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.6414, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(55.1045, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.9718, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(34.5139, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(43.1404, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.4341, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.1850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0719, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5232, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.9205, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7799, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.2645, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7459, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6431, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6602, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5185, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7316, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4712, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2427, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6074, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3634, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5670, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8859, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4809, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6896, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5662, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7113, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.7326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(113.5865, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8351, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9669, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4882, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9201, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1648, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6521, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7702, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9455, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6105, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2388, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5717, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8136, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0916, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6793, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1961, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0162, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1224, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2626, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1509, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5469, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7595, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.4125, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.1180, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0342, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.9394, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0157, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1627, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0791, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.8535, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(57.2217, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8351, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1509, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5751, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.5499, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8161, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.5051, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6202, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.5703, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6443, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4053, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(34.9994, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3665, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6239, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4707, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.4841, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0375, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6203, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6129, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.7882, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3901, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(44.7854, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4592, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1818, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4825, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1279, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0555, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6255, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8553, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3938, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3700, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.3460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.7035, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9547, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.3951, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7939, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.8479, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5217, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2448, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7297, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0273, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5263, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6109, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2794, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2128, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8978, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9814, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7271, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.1548, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4923, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6209, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5581, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2327, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.6381, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9969, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9365, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.8486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9451, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4568, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8044, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1239, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(44.2224, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.7233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.1320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1239, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4169, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.3237, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0402, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4509, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4055, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.4019, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7437, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.7994, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7360, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8806, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9658, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5459, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6794, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0373, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4778, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1441, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3925, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.0700, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5378, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8668, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4885, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4304, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(95.2980, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.4825, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.6467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(104.2372, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.5335, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.9518, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(73.0562, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.4201, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.2157, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.0033, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2532, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1321, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.8385, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.9510, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.6428, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.3636, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4465, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0550, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4060, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.4725, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.2009, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8606, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7491, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.3870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.7571, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4060, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.2908, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.3915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4060, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(80.4877, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6795, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(49.0726, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(54.1438, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.3481, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.8115, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1218, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.0802, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(44.5178, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3452, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8311, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.4390, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8007, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(67.7482, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.2870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0808, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3535, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.9110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(135.7746, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7861, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.0603, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.1354, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.3479, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.9809, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.5696, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1079, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1261, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0807, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2096, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7763, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9933, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4702, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7568, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.1798, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.2406, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.8689, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.6174, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.3384, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.3837, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.9892, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9097, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.4394, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.9503, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(72.0237, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.2340, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.9892, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9097, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.9503, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(72.0237, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.4048, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(43.6523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.9553, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.2256, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3659, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9993, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.7185, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(43.6523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8293, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.9553, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.6490, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3659, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8382, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(66.5703, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(29.0284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(78.8578, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.9078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0848, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2233, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0668, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.3875, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3412, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6017, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.6225, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.5448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(255.9088, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(57.1471, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(170.3916, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9660, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7625, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6454, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0890, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7081, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0672, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.5483, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3954, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2590, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9956, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7062, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9783, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4519, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3319, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6359, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5962, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8124, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1284, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5437, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.8685, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.3148, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0454, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7094, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9820, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0894, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2802, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9075, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.3995, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6197, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8112, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2811, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4972, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0008, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0400, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4276, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.3910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.5402, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(44.1312, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.7420, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.1239, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.8922, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.2644, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.3441, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.1232, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2312, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6739, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3740, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9433, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4212, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4522, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7462, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3675, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8018, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6146, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.2260, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4869, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6382, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6331, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0563, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.5946, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.8315, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9352, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0535, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.5116, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.7444, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.4096, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5413, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6739, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5027, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4507, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1614, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8018, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.8687, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.5946, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.8315, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9352, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7483, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0535, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3549, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.5368, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(67.5236, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3594, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.8607, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0948, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7036, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.9195, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.4468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.6183, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.4031, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9058, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4344, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.6946, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(21.3585, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.5334, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.7827, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7599, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4344, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9974, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(38.7791, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.6328, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.7093, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.1796, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.3777, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.6212, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5856, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4112, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.3224, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.3910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5491, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.8961, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(34.9007, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4908, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.0712, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5646, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.6066, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.3836, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.7339, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.5671, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(35.8943, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.0494, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4274, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.9710, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.8421, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.0062, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3043, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6910, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.0990, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1943, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3050, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3752, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7580, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.5931, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4101, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1763, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9750, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.7319, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.7699, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(36.9316, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.3534, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9444, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0903, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.8077, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.7514, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5900, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.0833, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(76.5219, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.6162, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.0096, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9755, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.5217, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.5356, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2484, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6821, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7800, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5396, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3175, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.1070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(60.7644, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.2747, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1448, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.2785, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6426, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8481, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.9610, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8720, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.6587, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.7418, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.8047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.9451, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.1200, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.5048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(245.8613, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.6483, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.7699, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.2462, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(31.8201, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(34.9517, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.6322, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(18.2059, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.0311, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.5958, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.6451, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(34.9653, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.4644, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(50.8686, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(42.0436, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(37.4805, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(59.7799, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(6.5017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(666.2615, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.2057, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(22.5727, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.0161, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.7006, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.4468, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.0479, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.8569, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3263, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.1447, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5753, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4695, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9678, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.8354, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5753, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.5486, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6213, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.9127, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9308, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8186, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(96.6661, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(37.3712, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4827, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.2855, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.7622, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.3638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(28.9000, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8513, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.6095, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.0320, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.7078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(49.4085, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8513, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.2213, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.9561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(19.2236, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0974, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(79.8404, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(40.0460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(92.6150, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(32.1776, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7628, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1091, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4177, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.5370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5069, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.8453, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3717, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.9471, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3295, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6787, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.8063, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.6451, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.1586, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.2973, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.6654, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.1915, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.2561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.0532, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7589, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3026, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3989, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6735, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9908, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3814, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5467, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6490, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9069, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.5552, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5342, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2064, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0609, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.2919, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5173, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9587, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3026, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2017, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.7370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6214, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2044, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2715, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5342, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.4393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.1202, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9382, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.1845, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.1234, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.9393, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(25.1234, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.0192, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.9998, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.4656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(11.7701, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(26.6925, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3637, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4063, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.4482, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.0512, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.0314, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9201, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7124, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.8307, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.7120, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.1575, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.1480, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.7198, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(93.9689, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5599, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(23.1074, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.1844, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(56.6993, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.7499, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.1437, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6556, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.6010, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9569, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6307, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.0523, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.5140, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.7210, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.0253, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0370, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7032, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2210, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(15.4054, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9297, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.7937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(16.3419, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.6988, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(79.2894, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.9606, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.7354, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.5533, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9969, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.8294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(46.0329, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.8484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(17.2598, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.5483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(12.7850, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3277, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.7342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(41.8548, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.6666, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8536, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3621, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.0870, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.1930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(24.3625, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.6240, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.4645, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.1045, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.3458, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(20.3352, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.2524, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4921, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4466, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3737, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.6623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.2713, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9349, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.9237, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.4085, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.2047, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.4280, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.4481, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.2990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(27.0861, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(37.9023, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.5492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.7078, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.2305, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(9.3048, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.7099, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.6222, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7795, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9270, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.8278, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.4490, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.1068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.2219, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(30.6751, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9151, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.3531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(10.5179, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.8802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(6.5545, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.5561, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.5951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(36.4205, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(39.4316, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.5818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(97.6876, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.9531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(52.0954, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(3.6900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(40.0460, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.4229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(83.3376, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(81.4304, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(4.3676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(78.8578, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(5.7491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(313.9109, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(13.8143, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.2598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.2967, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.6203, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.5673, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.8797, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.4095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(1.5061, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.9509, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.1917, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.1090, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.0922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.9807, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4767, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.9088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.4814, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.7134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.0410, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(0.8438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(2.3252, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.4804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(4.3948, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.9920, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.0901, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(8.0855, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(2.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(14.1438, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.1356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.1131, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.9559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(7.0705, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.2018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.3261, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.7270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(5.6235, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss:  tensor(1.3374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Perplexity:  tensor(3.8090, device='cuda:0', grad_fn=<ExpBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from bitsandbytes.optim import Adam8bit\n",
        "\n",
        "optimizer = Adam8bit(gpt.parameters(), lr=1e-7)\n",
        "gpt.gradient_checkpointing_enable()\n",
        "seq_length = 256\n",
        "\n",
        "losses = []\n",
        "perplexities = []\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "    for row in tqdm(train):\n",
        "        if len(row) <= 1:\n",
        "            continue\n",
        "\n",
        "        batch = tokenizer(row, truncation=True, max_length=seq_length, return_tensors='pt')\n",
        "        batch = {k: v.cuda() for k, v in batch.items()}\n",
        "\n",
        "        out = gpt.forward(**batch,)\n",
        "\n",
        "        loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n",
        "                               reduction='mean')\n",
        "        perplexity = torch.exp(loss)\n",
        "\n",
        "        print(\"Loss: \", loss)\n",
        "        print(\"Perplexity: \", perplexity)\n",
        "        losses.append(loss)\n",
        "        perplexities.append(perplexity)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Instruction: Generate code that creates a simple convolutional neural netwotk in pytorch.\n",
        "\n",
        "Answer: \"\"\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "generated_ids = gpt.generate(input_ids,\n",
        "                             do_sample=True,\n",
        "                             temperature=0.9,\n",
        "                             max_length=256)\n",
        "generated_text = tokenizer.decode(generated_ids[0])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "vt5GX0Lxe3rc",
        "outputId": "37551800-589b-435a-a5e1-686318f265cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction: Generate code that creates a simple convolutional neural netwotk in pytorch.\n",
            "\n",
            "Answer: \n",
            "    net = torch.nn.Sequential(\n",
            "    conv1x1(32, 3, 5),\n",
            "    conv1x1(64, 3, 5),\n",
            "    conv1x1(96, 3, 5)\n",
            ")\n",
            "\n",
            "Networks of this instruction will be available in pytorch.\n",
            "\n",
            "2. Convolutional Neural Networks in pytorch \n",
            "\n",
            "Instruction: Generate code that creates a simple convolutional neural netwotk in pytorch.\n",
            "\n",
            "Answer:\n",
            "    net = torch.nn.Sequential(\n",
            "                                                                                                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This training loop is just a proof of concept - to show that even in the heaviest case, it still fits on a gpu.\n",
        "Depending on your finetuning task, you'll need to remove some parts.\n",
        "Below we explain how to modify the code to achieve the setup from the [LoRA paper](https://arxiv.org/pdf/2106.09685.pdf)\n",
        "\n",
        "If you wanna fine-tune a-la LoRA , please use the parameters from Table 11,12 and 15 as a starter:\n",
        "\n",
        "(1) Train only the adapter matrices from attention layers\n",
        "\n",
        "In the above example, we train all kinds of adapters, and also layernorm scales and biases. This is only useful for fine-tuning over reasonably large datasets over long time.\n",
        "For quick setups you should tag everything except **the attention adapters** as `requires_grad=False` -- or just don't feed them into Adam:\n",
        "\n",
        "```\n",
        "\n",
        "params_for_optimizer = [\n",
        "    param for name, param in model.named_parameters()\n",
        "    if \"attn\" in name and \"adapter\" in name\n",
        "]\n",
        "print(\"Trainiable params:\", len(params_for_optimizer))\n",
        "\n",
        "# and after you verified it:\n",
        "for name, param in model.named_parameters():\n",
        "    if param not in params_for_optimizer:\n",
        "        print(f\"Setting {name} requires_grad=False\")\n",
        "        param.requires_grad = False\n",
        "```\n",
        "\n",
        "An even better way is to only create adapters that you need by modifying the `add_adapters` function above:\n",
        "```\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, (FrozenBNBLinear, FrozenBNBEmbedding)):\n",
        "        if \"attn\" in name:\n",
        "            print(\"Adding adapter to\", name)\n",
        "\n",
        "            todo_initialize_adapters_like_in_notebook()\n",
        "        else:\n",
        "            print(\"Not adding adapter to\", name)\n",
        "```\n",
        "As a side-effect, that would actually somewhat reduce the memory usage and may let you fit a longer sequence (e.g. 256)\n",
        "\n",
        "\n",
        "(2) initialize the second adapter matrix with zeros\n",
        "```\n",
        "for name, module in model.named_modules():\n",
        "    if hasattr(module, \"adapter\"):\n",
        "        print(\"Initializing\", name)\n",
        "        nn.init.zeros_(module.adapter[1].weight)\n",
        "        # optional: scale adapter[0].weight by (LoRA_alpha / r)\n",
        "```\n",
        "\n",
        "(3) use warmup and weight decay in Adam:\n",
        "```\n",
        "optimizer = Adam8Bit(..., weight_decay=0.01)\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps_from_paper(), expected_total_number_of_steps\n",
        ")\n",
        "\n",
        "actually_use_scheduler_in_training_loop()\n",
        "```\n",
        "\n",
        "Finally, we recommend modifying training loop to track the training metrics, saving the best checkpoint, etc."
      ],
      "metadata": {
        "id": "lx1T8Qvga-fN"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68537c4d2a104f1c83fa9c9480382172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4801f03243de45ac91843ae0f4153a94",
              "IPY_MODEL_000be633dc1342aeae502ca85090b373",
              "IPY_MODEL_6ef5b563cb6241b589ca1d44bb74d101"
            ],
            "layout": "IPY_MODEL_4393113513fe449995ad4f4f71cceea1"
          }
        },
        "4801f03243de45ac91843ae0f4153a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0390b09d8f141e594d8ac9274211dbb",
            "placeholder": "​",
            "style": "IPY_MODEL_8543cc8d203449c38dcd61011adaf346",
            "value": " 54%"
          }
        },
        "000be633dc1342aeae502ca85090b373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d360cd3269b494aaed85aa45e2fcac2",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72cf39fff1444f079a3d2a3a4947011e",
            "value": 2157
          }
        },
        "6ef5b563cb6241b589ca1d44bb74d101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e6fa43b9764ed7a030b5ac50673866",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe9850bd6bc402b88b0ce3272ad045d",
            "value": " 2157/4000 [28:23&lt;25:41,  1.20it/s]"
          }
        },
        "4393113513fe449995ad4f4f71cceea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0390b09d8f141e594d8ac9274211dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8543cc8d203449c38dcd61011adaf346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d360cd3269b494aaed85aa45e2fcac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cf39fff1444f079a3d2a3a4947011e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0e6fa43b9764ed7a030b5ac50673866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe9850bd6bc402b88b0ce3272ad045d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}